sf::st_transform(sf::st_crs("EPSG:6347")) |>
dplyr::filter(cluster == args[2]) |>
terra::vect()
ny_pts <- vect(here("Data/Training_Data/Northern_Allegheny_Plateau_training_pts.gpkg")) |>
terra::project("EPSG:6347")
cluster_target
tr <- rast(list.files(path = args[3], pattern = "041402011002", full.names = TRUE))
tr
tr <- (list.files(path = args[3], pattern = "041402011002", full.names = TRUE))
tr
lapply(list.files(path = args[3], pattern = "041402011002", full.names = TRUE), rast)
r <- (list.files(path = args[3], pattern = "041402011002", full.names = TRUE))[[1]]
r
r <- rast((list.files(path = args[3], pattern = "041402011002", full.names = TRUE))[[1]])
r
r <- list.files(path = args[3], pattern = "041402011002", full.names = TRUE)
r
rename_layers_func <- function(rast_list){
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
return(huc)
}
print(huc)
}
rename_layers_func(r)
r
rename_layers_func <- function(rast_list){
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
}
print(scale)
}
rename_layers_func(r)
rename_layers_func <- function(rast_list){
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
print(scale)
}
}
rename_layers_func(r)
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
print(huc+scale)
}
rename_layers_func <- function(rast_list){
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
print(huc+scale)
}
}
rename_layers_func(r)
rename_layers_func <- function(rast_list){
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
print(cat(huc,scale))
}
}
rename_layers_func(r)
r <- list.files(path = args[3], pattern = "041402011002", full.names = TRUE)
rename_layers_func <- function(rast_list){
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
print(cat(huc,scale))
}
}
rename_layers_func(r)
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
print(cat(scale))
}
rename_layers_func <- function(rast_list){
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
print(cat(scale))
}
}
rename_layers_func(r)
rename_layers_func <- function(rast_list){
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
print(scale)
}
}
rename_layers_func(r)
rename_layers_func <- function(rast_list){
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
cat(scale)
}
}
rename_layers_func(r)
r
rast(r[[1]])
rast(r[[4]])
rast(r[[4]]) |> rename_with(paste0("_10m"))
rast(r[[4]]) |> tidyterra::rename_with(paste0("_10m"))
rast(r[[4]]) |> tidyterra::rename_with(toupper)
rast(r[[4]]) |> tidyterra::rename_with(cat("100m"))
rast(r[[4]]) |> tidyterra::rename_with(cat)
rast(r[[4]]) |> tidyterra::rename_with(cat(.x, "10m"))
rast(r[[4]]) |> tidyterra::rename_with(~cat(.x, "10m"))
rast(r[[4]])
rast(r[[4]]) %>% tidyterra::rename_with(~cat(.x, "10m"))
rast(r[[4]]) |> tidyterra::rename_with(~cat(., "10m"))
rast(r[[4]]) |> tidyterra::rename_with(~paste0(., "10m"))
rast(r[[4]]) |> tidyterra::rename_with(~paste0(.x, "10m"))
rename_layers_func <- function(rast_list){
rename_layers_func <- function(rast_list){
for(i in rast_list){
huc <- str_extract(i, "(?<=huc_)\\d+")
scale <- str_extract(i, "\\d+m")
if(str_detect(scale, "10m")){
r <- rast(i) |> tidyterra::rename_with(~paste0(.x, "10m"))}
else if(str_detect(scale, "100m"){
rename_layers_func <- function(rast_list){
renamed_rast_list <- list()
for(i in 1:length(rast_list)){
ri <- rast(rast_list[[i]])
huc <- str_extract(ri, "(?<=huc_)\\d+")
scale <- str_extract(ri, "\\d+m")
if(str_detect(scale, "10m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "10m"))}
else if(str_detect(scale, "100m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "100m"))}
else if(str_detect(scale, "1000m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "1000m"))}
renamed_rast_list[[i]] <- r
}
return(renamed_rast_list)
}
r
system.time(
named_r <- rename_layers_func(r)
)
r[[1]]
rename_layers_func <- function(rast_list){
renamed_rast_list <- list()
for(i in 1:length(rast_list)){
ri <- rast(rast_list[[i]])
huc <- str_extract(rast_list[[i]], "(?<=huc_)\\d+")
scale <- str_extract(rast_list[[i]], "\\d+m")
if(str_detect(scale, "10m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "10m"))}
else if(str_detect(scale, "100m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "100m"))}
else if(str_detect(scale, "1000m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "1000m"))}
renamed_rast_list[[i]] <- r
}
return(renamed_rast_list)
}
system.time(
named_r <- rename_layers_func(r)
)
named_r
str_extract(r[[i]], "(?<=huc_)\\d+")
cluster_target |> tidyterra::filter(huc12 == str_extract(r[[i]], "(?<=huc_)\\d+"))
r <- list.files(path = args[3], pattern = "m.tif", full.names = TRUE)
r
rename_layers_func <- function(rast_list){
renamed_rast_list <- list()
pts_list <- list()
for(i in 1:length(rast_list)){
ri <- rast(rast_list[[i]])
scale <- str_extract(rast_list[[i]], "\\d+m")
if(str_detect(scale, "10m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "10m"))}
else if(str_detect(scale, "100m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "100m"))}
else if(str_detect(scale, "1000m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "1000m"))}
else (r <- ri)
renamed_rast_list[[i]] <- r
}
return(renamed_rast_list)
}
system.time(
named_r <- rename_layers_func(r)
)
named_r
sources(named_r[[1]])
crs(named_r[[1]])
crs(named_r[[1]], describe = TRUE)
describe(named_r[[1]])
crs(named_r[[1]], describe = TRUE)
desc <- crs(named_r[[1]], describe = TRUE)
desc$code
crs(named_r[[1]], describe = TRUE)["code"]
crs(named_r[[1]], describe = TRUE)["code"] == 6347
isTRUE(crs(named_r[[1]], describe = TRUE)["code"] == 6347)
for(i in 1:length(cluster_target["huc12"])){
huc_name <- values(cluster_target[i]["huc12"])[[1]]
print(huc_name)
#huc_pts <- terra::crop(ny_pts, cluster_target[i])
#tr <- rast(list.files(path = args[3], pattern = huc_name, full.names = TRUE))
}
cluster_target["huc12" == "041402011002"]
cluster_target["huc12"]
cluster_target$huc12 == "041402011002"
terra::subset(cluster_target)
cluster_target |> tidyterra::filter(huc12 == "041402011002")
for(i in 1:length(cluster_target["huc12"])){
huc_name <- values(cluster_target[i]["huc12"])[[1]]
huc <- cluster_target |> tidyterra::filter(huc12 == huc_name)
print(huc)
#huc_pts <- terra::crop(ny_pts, cluster_target["huc12"])
#tr <- rast(list.files(path = args[3], pattern = huc_name, full.names = TRUE))
}
rename_layers_func <- function(rast_list){
renamed_rast_list <- list()
pts_list <- list()
for(i in 1:length(rast_list)){
ri <- rast(rast_list[[i]])
scale <- str_extract(rast_list[[i]], "\\d+m")
if(str_detect(scale, "10m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "10m"))}
else if(str_detect(scale, "100m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "100m"))}
else if(str_detect(scale, "1000m")){r <- ri |> tidyterra::rename_with(~paste0(.x, "1000m"))}
else (r <- ri)
renamed_rast_list[[i]] <- r
}
return(renamed_rast_list)
}
system.time(
named_terrain_r <- rename_layers_func(r)
)
named_terrain_r
pts_list <- list()
for(i in 1:length(cluster_target["huc12"])){
huc_name <- values(cluster_target[i]["huc12"])[[1]]
huc <- cluster_target |> tidyterra::filter(huc12 == huc_name)
print(huc)
pts_list[[i]] <- terra::crop(ny_pts, huc)
#tr <- rast(list.files(path = args[3], pattern = huc_name, full.names = TRUE))
}
pts_list
pts_list[[1]]
my_named_list <- list(
Name = "Alice",
Age = 30,
City = "New York"
)
names(my_named_list)
names(my_named_list[[1]])
names(my_named_list[1])
pts_list <- list()
for(i in 1:length(cluster_target["huc12"])){
huc_name <- values(cluster_target[i]["huc12"])[[1]]
huc <- cluster_target |> tidyterra::filter(huc12 == huc_name)
print(huc)
pts_list[[i]] <- terra::crop(ny_pts, huc)
names(pts_list[i]) <- huc_name
#tr <- rast(list.files(path = args[3], pattern = huc_name, full.names = TRUE))
}
pts_list
names(pts_list)
my_named_list[1]
my_named_list[1] <- "Randy"
my_named_list <- list(
Name = "Alice",
Age = 30,
City = "New York"
)
names(my_named_list[1])
names(my_named_list[1]) <- "Named"
names(my_named_list[1])
sources(pts_list[[1]])
sources(pts_list[[1]]) <- "test"
sources(pts_list[[1]])
values(cluster_target["huc12"])
names(pts_list) <- values(cluster_target["huc12"])
names(pts_list)
names(pts_list) <- NA
ls
names(pts_list)
pts_list
as.list(values(cluster_target["huc12"]))
names(pts_list) <- as.list(values(cluster_target["huc12"]))
pts_list
names(pts_list)
names(pts_list) <- NA
name(pts_list)
names(pts_list)
as.vector(values(cluster_target["huc12"]))
as.vector(values(cluster_target["huc12"]))[[1]]
names(pts_list) <- as.vector(values(cluster_target["huc12"]))[[1]]
names(pts_list)
plot(cluster_target |> tidyterra::filter(huc12 == "041402011002"))
plot(pts_list$041402011002, add = TRUE)
pts_list$041402011002
pts_list$"041402011002"
plot(pts_list$"041402011002", add = TRUE)
named_terrain_r
raster_stack_extract <- function(rast_list, hydro_rast_list, pts_list){
for(i in 1:length(cluster_target["huc12"])){
huc_name <- as.character(values(cluster_target[i]["huc12"])[[1]])
pts_list$huc_name
}
}
raster_stack_extract(rast_list = named_terrain_r, hydro_rast_list = "", pts_list = pts_list)
raster_stack_extract <- function(rast_list, hydro_rast_list, pts_list){
for(i in 1:length(cluster_target["huc12"])){
huc_name <- as.character(values(cluster_target[i]["huc12"])[[1]])
print(pts_list$huc_name)
}
}
raster_stack_extract(rast_list = named_terrain_r, hydro_rast_list = "", pts_list = pts_list)
pts_list
pts_list$041402011002
pts_list$`041402011002`
pts_list == 041402011002
pts_list == "041402011002"
"041402011002" %in% pts_list
`041402011002` %in% pts_list
041402011002 %in% pts_list
pts_list
pts_list[[1]]
# The function should take a arguments to subset ecoregions/study areas and produce NWI sample points within them
training_pts_func <- function(ids, areas = ny_areas, nwi = ny_nwi) {
# The target area is the single ecoregion or area from within NY State
target <- tidyterra::filter(areas, !!as.symbol(ID) == as.numeric(ids[[1]]))
# target_name is for saving the files
target_name <- ids[[1]]
# print(target_name)
# # target_area is the area dissolved/aggregated to a single polygon
# target_area <- target |>
#     terra::aggregate()
# target_area$US_L3NAME <- target_name
# #print(names(target_area))
# Reduce/crop the NWI wetlands to within target
nwi_area_crop <- terra::crop(x = nwi, y = target)
# print(nwi_area_crop)
# Reclassify wetlands in the cropped NWI to Forested, Emergent, or Scrub Shrub
nwi_area_filter <- nwi_area_crop |>
tidyterra::mutate(WetClass = case_when(str_detect(ATTRIBUTE, "PSS") & !str_detect(ATTRIBUTE, "PFO|PEM") ~ "ScrubShrub",
str_detect(ATTRIBUTE, "PEM") & !str_detect(ATTRIBUTE, "PFO|PSS") ~ "Emergent",
str_detect(ATTRIBUTE, "PFO") & !str_detect(ATTRIBUTE, "PSS|PEM") ~ "Forested",
str_detect(ATTRIBUTE, "PSS") & str_detect(ATTRIBUTE, "PFO") ~ "ForestedScrub",
str_detect(ATTRIBUTE, "PSS") & str_detect(ATTRIBUTE, "PEM") ~ "EmergentScrub",
.default = ATTRIBUTE))
# The number of different wetland polygons in the cropped NWI
numEMW <- length(nwi_area_filter[nwi_area_filter$WetClass == "Emergent"])
numFSW <- length(nwi_area_filter[nwi_area_filter$WetClass == "Forested"])
numSSW <- length(nwi_area_filter[nwi_area_filter$WetClass == "ScrubShrub"])
# The NWI wetland points are created turning NWI polygons to points
nwi_pts_wet <- nwi_area_filter |>
terra::buffer(-10) |> # a negative buffer should remove points on the lines
terra::as.points() |> # turn the polygons into points
dplyr::mutate(MOD_CLASS = case_when(WetClass == "Emergent" ~ "EMW", #MOD_CLASS is for modeling
WetClass == "Forested" ~ "FSW",
WetClass == "ScrubShrub" ~ "SSW",
.default = "Other"),
COARSE_CLASS = "WET") |> # COARSE CLASS is for simple modeling
dplyr::select(MOD_CLASS, COARSE_CLASS)
nwi_pts_wet <- sample(nwi_pts_wet, size = 0.70*nrow(nwi_pts_wet))  |> # 70% of the NWI points
# Upland points are defined as outside the NWI polygons
# Might have some commission error/included wetlands, so there are many of these
# Generate a random number of points in the area of interest
pts <- terra::spatSample(target, method = "random", size = 5E5)
# reverse mask the random number of points outside NWI polygons
nwi_pts_upl <- terra::mask(pts, nwi_area_crop |> buffer(10), inverse = TRUE) |>
dplyr::mutate(MOD_CLASS = "UPL",
COARSE_CLASS = "UPL") |>
dplyr::select(MOD_CLASS, COARSE_CLASS)
# Combine upland and wetland points
nwi_pts_all <- rbind(nwi_pts_upl, nwi_pts_wet)
# # The number of wetland points to balance the classes a bit
# numFSW_pts <- nrow(nwi_pts_all[nwi_pts_all$MOD_CLASS == "FSW", ])
# numEMW_pts <- nrow(nwi_pts_all[nwi_pts_all$MOD_CLASS == "EMW", ])
# numSSW_pts <- nrow(nwi_pts_all[nwi_pts_all$MOD_CLASS == "SSW", ])
#
# # If there are fewer than half of emergent and scrub/shrub vs. forested then supplement the points by sampling
#     # additional emergent polygons
# if(numEMW_pts < 0.5*numFSW_pts & numSSW_pts < 0.5*numFSW_pts ){
#     suppPointsEMW <- nwi_area_filter |>
#         dplyr::filter(str_detect(WetClass, "Emergent")) |>
#         terra::buffer(-10) |> # a negative buffer should remove points on the lines
#         terra::as.points() |>
#         sample(size = c(0.5*numFSW_pts, 1000)[which.max(c(0.5*numFSW_pts, 1000))])  |>
#         dplyr::mutate(MOD_CLASS = "EMW",
#                       COARSE_CLASS = "WET") |>
#         dplyr::select(MOD_CLASS, COARSE_CLASS)
#     suppPointsSSW <- nwi_area_filter |>
#       dplyr::filter(str_detect(WetClass, "ScrubShrub")) |>
#       terra::buffer(-10) |> # a negative buffer should remove points on the lines
#       terra::as.points() |>
#       sample(size = c(0.5*numFSW_pts, 1000)[which.max(c(0.5*numFSW_pts, 1000))])  |>
#       dplyr::mutate(MOD_CLASS = "SSW",
#                     COARSE_CLASS = "WET") |>
#       dplyr::select(MOD_CLASS, COARSE_CLASS)
#
#     nwi_pts_all_supp <- rbind(nwi_pts_all, suppPointsEMW, suppPointsSSW)
# } else { #don't change if > half of forested/scrub/shrub
#     nwi_pts_all_supp <- nwi_pts_all
# }
#
# # Summary of point distribution
# print(nwi_pts_all_supp |> as.data.frame() |>  dplyr::group_by(MOD_CLASS) |> dplyr::summarise(count = n()))
#
# # Saving files for both the study area and the training data points
# # writeVector(target, paste0("Data/NY_Ecoregions/",
# #                                 target_name,
# #                                #"_",
# #                                #ids,
# #                                "_ECO.gpkg"),
# #             overwrite = TRUE)
# writeVector(nwi_pts_all_supp, paste0("Data/Training_Data/",
#                                      args[3],"_",
#                                      target_name,
#                                      #"_",
#                                      #ids,
#                                      "_training_pts.gpkg"), overwrite = TRUE)
}
# The function should take a arguments to subset ecoregions/study areas and produce NWI sample points within them
training_pts_func <- function(ids, areas = ny_areas, nwi = ny_nwi) {
# The target area is the single ecoregion or area from within NY State
target <- tidyterra::filter(areas, !!as.symbol(ID) == as.numeric(ids[[1]]))
# target_name is for saving the files
target_name <- ids[[1]]
# print(target_name)
# # target_area is the area dissolved/aggregated to a single polygon
# target_area <- target |>
#     terra::aggregate()
# target_area$US_L3NAME <- target_name
# #print(names(target_area))
# Reduce/crop the NWI wetlands to within target
nwi_area_crop <- terra::crop(x = nwi, y = target)
# print(nwi_area_crop)
# Reclassify wetlands in the cropped NWI to Forested, Emergent, or Scrub Shrub
nwi_area_filter <- nwi_area_crop |>
tidyterra::mutate(WetClass = case_when(str_detect(ATTRIBUTE, "PSS") & !str_detect(ATTRIBUTE, "PFO|PEM") ~ "ScrubShrub",
str_detect(ATTRIBUTE, "PEM") & !str_detect(ATTRIBUTE, "PFO|PSS") ~ "Emergent",
str_detect(ATTRIBUTE, "PFO") & !str_detect(ATTRIBUTE, "PSS|PEM") ~ "Forested",
str_detect(ATTRIBUTE, "PSS") & str_detect(ATTRIBUTE, "PFO") ~ "ForestedScrub",
str_detect(ATTRIBUTE, "PSS") & str_detect(ATTRIBUTE, "PEM") ~ "EmergentScrub",
.default = ATTRIBUTE))
# The number of different wetland polygons in the cropped NWI
numEMW <- length(nwi_area_filter[nwi_area_filter$WetClass == "Emergent"])
numFSW <- length(nwi_area_filter[nwi_area_filter$WetClass == "Forested"])
numSSW <- length(nwi_area_filter[nwi_area_filter$WetClass == "ScrubShrub"])
# The NWI wetland points are created turning NWI polygons to points
nwi_pts_wet <- nwi_area_filter |>
terra::buffer(-10) |> # a negative buffer should remove points on the lines
terra::as.points() |> # turn the polygons into points
dplyr::mutate(MOD_CLASS = case_when(WetClass == "Emergent" ~ "EMW", #MOD_CLASS is for modeling
WetClass == "Forested" ~ "FSW",
WetClass == "ScrubShrub" ~ "SSW",
.default = "Other"),
COARSE_CLASS = "WET") |> # COARSE CLASS is for simple modeling
dplyr::select(MOD_CLASS, COARSE_CLASS)
nwi_pts_wet <- sample(nwi_pts_wet, size = 0.70*nrow(nwi_pts_wet))  |> # 70% of the NWI points
# Upland points are defined as outside the NWI polygons
# Might have some commission error/included wetlands, so there are many of these
# Generate a random number of points in the area of interest
pts <- terra::spatSample(target, method = "random", size = 5E5)
# reverse mask the random number of points outside NWI polygons
# nwi_pts_upl <- terra::mask(pts, nwi_area_crop |> buffer(10), inverse = TRUE) |>
#     dplyr::mutate(MOD_CLASS = "UPL",
#                   COARSE_CLASS = "UPL") |>
#     dplyr::select(MOD_CLASS, COARSE_CLASS)
#
# # Combine upland and wetland points
# nwi_pts_all <- rbind(nwi_pts_upl, nwi_pts_wet)
# # The number of wetland points to balance the classes a bit
# numFSW_pts <- nrow(nwi_pts_all[nwi_pts_all$MOD_CLASS == "FSW", ])
# numEMW_pts <- nrow(nwi_pts_all[nwi_pts_all$MOD_CLASS == "EMW", ])
# numSSW_pts <- nrow(nwi_pts_all[nwi_pts_all$MOD_CLASS == "SSW", ])
#
# # If there are fewer than half of emergent and scrub/shrub vs. forested then supplement the points by sampling
#     # additional emergent polygons
# if(numEMW_pts < 0.5*numFSW_pts & numSSW_pts < 0.5*numFSW_pts ){
#     suppPointsEMW <- nwi_area_filter |>
#         dplyr::filter(str_detect(WetClass, "Emergent")) |>
#         terra::buffer(-10) |> # a negative buffer should remove points on the lines
#         terra::as.points() |>
#         sample(size = c(0.5*numFSW_pts, 1000)[which.max(c(0.5*numFSW_pts, 1000))])  |>
#         dplyr::mutate(MOD_CLASS = "EMW",
#                       COARSE_CLASS = "WET") |>
#         dplyr::select(MOD_CLASS, COARSE_CLASS)
#     suppPointsSSW <- nwi_area_filter |>
#       dplyr::filter(str_detect(WetClass, "ScrubShrub")) |>
#       terra::buffer(-10) |> # a negative buffer should remove points on the lines
#       terra::as.points() |>
#       sample(size = c(0.5*numFSW_pts, 1000)[which.max(c(0.5*numFSW_pts, 1000))])  |>
#       dplyr::mutate(MOD_CLASS = "SSW",
#                     COARSE_CLASS = "WET") |>
#       dplyr::select(MOD_CLASS, COARSE_CLASS)
#
#     nwi_pts_all_supp <- rbind(nwi_pts_all, suppPointsEMW, suppPointsSSW)
# } else { #don't change if > half of forested/scrub/shrub
#     nwi_pts_all_supp <- nwi_pts_all
# }
#
# # Summary of point distribution
# print(nwi_pts_all_supp |> as.data.frame() |>  dplyr::group_by(MOD_CLASS) |> dplyr::summarise(count = n()))
#
# # Saving files for both the study area and the training data points
# # writeVector(target, paste0("Data/NY_Ecoregions/",
# #                                 target_name,
# #                                #"_",
# #                                #ids,
# #                                "_ECO.gpkg"),
# #             overwrite = TRUE)
# writeVector(nwi_pts_all_supp, paste0("Data/Training_Data/",
#                                      args[3],"_",
#                                      target_name,
#                                      #"_",
#                                      #ids,
#                                      "_training_pts.gpkg"), overwrite = TRUE)
}
dplyr::sample_n
?dplyr::sample_n
