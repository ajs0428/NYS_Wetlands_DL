{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3583e01-89ae-4abe-88ce-8e934463a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibstorage/anthony/NYS_Wetlands_GHG\n",
      "Current working directory is now: /ibstorage/anthony/NYS_Wetlands_GHG\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "workdir = Path(\"/ibstorage/anthony/NYS_Wetlands_GHG/\")\n",
    "print(workdir)\n",
    "os.chdir(workdir)\n",
    "current_working_dir = Path.cwd()\n",
    "print(f\"Current working directory is now: {current_working_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae73200d-0d58-47c7-9376-4f1e08509129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48bbcd14-3964-4a07-8843-9c57e62c5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "naip_path = \"Data/NAIP/HUC_NAIP_Processed/cluster_208_huc_041402011002_NAIP_metrics.tif\"\n",
    "dem_path = \"Data/TerrainProcessed/HUC_DEMs/cluster_208_huc_041402011002.tif\"\n",
    "slp_path = \"Data/TerrainProcessed/HUC_TerrainMetrics/cluster_208_huc_041402011002_terrain_slp_5m.tif\"\n",
    "labels_path = \"Data/Training_Data/cluster_208_huc_041402011002_labels.tif\"\n",
    "wetlands_path = \"Data/Training_Data/HUC_Extracted_Training_Data/cluster_208_huc_041402011002_NWI.gpkg\"\n",
    "output_dir = Path(\"Data/Patches_v2\")\n",
    "\n",
    "patch_size = 256\n",
    "max_offset = 32  # Random offset from centroid (pixels) to add variety\n",
    "background_patches = 100  # Number of random background patches to include\n",
    "val_split = 0.2\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ea05390-ddfe-418c-9b71-437ad2c813c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rasters...\n",
      "Input stack shape: (11, 12000, 18000)\n",
      "Labels shape: (12000, 18000)\n"
     ]
    }
   ],
   "source": [
    "# === CREATE OUTPUT DIRECTORY ===\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === LOAD ALL BANDS ===\n",
    "print(\"Loading rasters...\")\n",
    "\n",
    "with rasterio.open(naip_path) as src:\n",
    "    naip = src.read()  # Shape: (6, H, W)\n",
    "    \n",
    "with rasterio.open(dem_path) as src:\n",
    "    dem = src.read()  # Shape: (1, H, W)\n",
    "    \n",
    "with rasterio.open(slp_path) as src:\n",
    "    slp = src.read()  # Shape: (1, H, W)\n",
    "\n",
    "with rasterio.open(labels_path) as src:\n",
    "    labels = src.read(1)  # Shape: (H, W)\n",
    "\n",
    "# Stack inputs: (7, H, W)\n",
    "inputs = np.vstack([naip, dem, slp])\n",
    "print(f\"Input stack shape: {inputs.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "654f3412-ca5a-4309-9344-3e0455f1c810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting patches...\n",
      "Total possible patches: 3220\n",
      "Patches with wetlands: 398\n",
      "Background-only patches: 438\n"
     ]
    }
   ],
   "source": [
    "# === LOAD WETLAND POLYGONS ===\n",
    "print(\"\\nLoading wetland polygons...\")\n",
    "wetlands = gpd.read_file(wetlands_path)\n",
    "print(f\"Number of wetland polygons: {len(wetlands)}\")\n",
    "\n",
    "# === HELPER FUNCTION: EXTRACT PATCH ===\n",
    "def extract_patch(center_row, center_col, patch_size, inputs, labels):\n",
    "    \"\"\"\n",
    "    Extract a patch centered at (center_row, center_col).\n",
    "    Returns None if patch would be out of bounds or contains NaN.\n",
    "    \"\"\"\n",
    "    half = patch_size // 2\n",
    "    \n",
    "    # Calculate bounds\n",
    "    row_start = center_row - half\n",
    "    row_end = center_row + half\n",
    "    col_start = center_col - half\n",
    "    col_end = center_col + half\n",
    "    \n",
    "    # Check bounds\n",
    "    if row_start < 0 or row_end > height or col_start < 0 or col_end > width:\n",
    "        return None, None\n",
    "    \n",
    "    # Extract patches\n",
    "    X_patch = inputs[:, row_start:row_end, col_start:col_end]\n",
    "    y_patch = labels[row_start:row_end, col_start:col_end]\n",
    "    \n",
    "    # Check for NaN\n",
    "    if np.any(np.isnan(X_patch)):\n",
    "        return None, None\n",
    "    \n",
    "    return X_patch, y_patch\n",
    "\n",
    "# === EXTRACT WETLAND-CENTERED PATCHES ===\n",
    "print(\"\\nExtracting wetland-centered patches...\")\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "wetland_patches_X = []\n",
    "wetland_patches_y = []\n",
    "skipped_count = 0\n",
    "\n",
    "for idx, row in wetlands.iterrows():\n",
    "    # Get centroid coordinates\n",
    "    centroid = row.geometry.centroid\n",
    "    \n",
    "    # Convert geographic coordinates to pixel coordinates\n",
    "    # transform: (x, y) -> (col, row)\n",
    "    col, row_px = ~transform * (centroid.x, centroid.y)\n",
    "    col, row_px = int(col), int(row_px)\n",
    "    \n",
    "    # Add random offset for variety\n",
    "    offset_row = np.random.randint(-max_offset, max_offset + 1)\n",
    "    offset_col = np.random.randint(-max_offset, max_offset + 1)\n",
    "    center_row = row_px + offset_row\n",
    "    center_col = col + offset_col\n",
    "    \n",
    "    # Extract patch\n",
    "    X_patch, y_patch = extract_patch(center_row, center_col, patch_size, inputs, labels)\n",
    "    \n",
    "    if X_patch is not None:\n",
    "        wetland_patches_X.append(X_patch)\n",
    "        wetland_patches_y.append(y_patch)\n",
    "    else:\n",
    "        skipped_count += 1\n",
    "\n",
    "print(f\"Wetland-centered patches extracted: {len(wetland_patches_X)}\")\n",
    "print(f\"Skipped (out of bounds or NaN): {skipped_count}\")\n",
    "\n",
    "# === EXTRACT RANDOM BACKGROUND PATCHES ===\n",
    "print(f\"\\nExtracting {background_patches} random background patches...\")\n",
    "\n",
    "background_patches_X = []\n",
    "background_patches_y = []\n",
    "attempts = 0\n",
    "max_attempts = background_patches * 10  # Limit attempts to avoid infinite loop\n",
    "\n",
    "while len(background_patches_X) < background_patches and attempts < max_attempts:\n",
    "    attempts += 1\n",
    "    \n",
    "    # Random center point\n",
    "    center_row = np.random.randint(patch_size // 2, height - patch_size // 2)\n",
    "    center_col = np.random.randint(patch_size // 2, width - patch_size // 2)\n",
    "    \n",
    "    # Extract patch\n",
    "    X_patch, y_patch = extract_patch(center_row, center_col, patch_size, inputs, labels)\n",
    "    \n",
    "    if X_patch is None:\n",
    "        continue\n",
    "    \n",
    "    # Only keep if it's purely background (no wetland pixels)\n",
    "    if not np.any(y_patch > 0):\n",
    "        background_patches_X.append(X_patch)\n",
    "        background_patches_y.append(y_patch)\n",
    "\n",
    "print(f\"Background patches extracted: {len(background_patches_X)}\")\n",
    "\n",
    "# === COMBINE AND SPLIT ===\n",
    "print(\"\\nCombining and splitting data...\")\n",
    "\n",
    "all_X = wetland_patches_X + background_patches_X\n",
    "all_y = wetland_patches_y + background_patches_y\n",
    "\n",
    "X_array = np.array(all_X, dtype=np.float32)\n",
    "y_array = np.array(all_y, dtype=np.uint8)\n",
    "\n",
    "print(f\"Total patches: {len(X_array)}\")\n",
    "print(f\"X shape: {X_array.shape}\")  # (N, 7, 256, 256)\n",
    "print(f\"y shape: {y_array.shape}\")  # (N, 256, 256)\n",
    "\n",
    "# Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_array, y_array, \n",
    "    test_size=val_split, \n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain patches: {len(X_train)}\")\n",
    "print(f\"Validation patches: {len(X_val)}\")\n",
    "\n",
    "# === SAVE PATCHES ===\n",
    "np.save(output_dir / \"X_train.npy\", X_train)\n",
    "np.save(output_dir / \"y_train.npy\", y_train)\n",
    "np.save(output_dir / \"X_val.npy\", X_val)\n",
    "np.save(output_dir / \"y_val.npy\", y_val)\n",
    "\n",
    "print(f\"\\nSaved patches to {output_dir}\")\n",
    "\n",
    "# === CLASS DISTRIBUTION IN TRAINING SET ===\n",
    "print(\"\\nClass distribution in training patches (pixel counts):\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "total = y_train.size\n",
    "for val, count in zip(unique, counts):\n",
    "    class_name = {0: 'Background', 1: 'EMW', 2: 'FSW', 3: 'SSW', 4: 'OWW'}.get(val, 'Unknown')\n",
    "    pct = (count / total) * 100\n",
    "    print(f\"  {class_name}: {count:,} pixels ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "719efb5b-353d-4315-bd6b-f9028ebf5983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled background patches: 43\n"
     ]
    }
   ],
   "source": [
    "# === SAMPLE BACKGROUND PATCHES ===\n",
    "np.random.seed(random_seed)\n",
    "n_background_keep = int(len(background_patches_X) * background_sample_ratio)\n",
    "background_indices = np.random.choice(\n",
    "    len(background_patches_X), \n",
    "    size=n_background_keep, \n",
    "    replace=False\n",
    ")\n",
    "\n",
    "sampled_bg_X = [background_patches_X[i] for i in background_indices]\n",
    "sampled_bg_y = [background_patches_y[i] for i in background_indices]\n",
    "\n",
    "print(f\"Sampled background patches: {len(sampled_bg_X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f90f598-b413-4db7-b50b-95db3edc3fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total patches: 441\n",
      "X shape: (441, 7, 256, 256)\n",
      "y shape: (441, 256, 256)\n",
      "\n",
      "Train patches: 352\n",
      "Validation patches: 89\n"
     ]
    }
   ],
   "source": [
    "# === COMBINE AND SPLIT ===\n",
    "all_X = wetland_patches_X + sampled_bg_X\n",
    "all_y = wetland_patches_y + sampled_bg_y\n",
    "\n",
    "X_array = np.array(all_X, dtype=np.float32)\n",
    "y_array = np.array(all_y, dtype=np.uint8)\n",
    "\n",
    "print(f\"\\nTotal patches: {len(X_array)}\")\n",
    "print(f\"X shape: {X_array.shape}\")  # (N, 7, 128, 128)\n",
    "print(f\"y shape: {y_array.shape}\")  # (N, 128, 128)\n",
    "\n",
    "# Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_array, y_array, \n",
    "    test_size=val_split, \n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain patches: {len(X_train)}\")\n",
    "print(f\"Validation patches: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9f984ed-2054-493a-b1c0-5fe0500112c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved patches to Data/Patches\n",
      "\n",
      "Class distribution in training patches (pixel counts):\n",
      "  Background: 19,837,679 pixels (85.99%)\n",
      "  EMW: 527,896 pixels (2.29%)\n",
      "  FSW: 1,357,839 pixels (5.89%)\n",
      "  SSW: 1,157,860 pixels (5.02%)\n",
      "  OWW: 187,398 pixels (0.81%)\n"
     ]
    }
   ],
   "source": [
    "# === SAVE PATCHES ===\n",
    "np.save(output_dir / \"X_train.npy\", X_train)\n",
    "np.save(output_dir / \"y_train.npy\", y_train)\n",
    "np.save(output_dir / \"X_val.npy\", X_val)\n",
    "np.save(output_dir / \"y_val.npy\", y_val)\n",
    "\n",
    "print(f\"\\nSaved patches to {output_dir}\")\n",
    "\n",
    "# === CLASS DISTRIBUTION IN TRAINING SET ===\n",
    "print(\"\\nClass distribution in training patches (pixel counts):\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "total = y_train.size\n",
    "for val, count in zip(unique, counts):\n",
    "    class_name = {0: 'Background', 1: 'EMW', 2: 'FSW', 3: 'SSW', 4: 'OWW'}.get(val, 'Unknown')\n",
    "    pct = (count / total) * 100\n",
    "    print(f\"  {class_name}: {count:,} pixels ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95c77f28-28b7-4352-93c5-12c10f7ccd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: min=0.00, max=255.00, mean=94.74\n",
      "G: min=19.00, max=255.00, mean=127.76\n",
      "B: min=55.00, max=255.00, mean=126.93\n",
      "NIR: min=12.00, max=255.00, mean=184.27\n",
      "NDWI: min=-0.79, max=1.00, mean=0.33\n",
      "NDVI: min=-0.70, max=0.82, mean=-0.18\n",
      "DEM: min=311.67, max=495.94, mean=363.50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load(\"Data/Patches/X_train.npy\")\n",
    "\n",
    "band_names = ['R', 'G', 'B', 'NIR', 'NDWI', 'NDVI', 'DEM']\n",
    "for i, name in enumerate(band_names):\n",
    "    band = X_train[:, i, :, :]\n",
    "    print(f\"{name}: min={band.min():.2f}, max={band.max():.2f}, mean={band.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f4ee2-e7ac-47e8-b8cf-d1d530657eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee7eae-4732-4434-bf21-55ef0bda849c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wetland-cnn",
   "language": "python",
   "name": "wetland-cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
