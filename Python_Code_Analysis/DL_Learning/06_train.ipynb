{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5c3bf5-9201-4c7f-b5b6-7622df105d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Anthony/Data and Analysis Local/NYS_Wetlands_GHG\n",
      "Current working directory is now: /Users/Anthony/Data and Analysis Local/NYS_Wetlands_GHG\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "workdir = Path(\"/Users/Anthony/Data and Analysis Local/NYS_Wetlands_GHG/\")\n",
    "print(workdir)\n",
    "os.chdir(workdir)\n",
    "current_working_dir = Path.cwd()\n",
    "print(f\"Current working directory is now: {current_working_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b38b106-673a-4eb4-8628-95db182d4e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Anthony/Data and Analysis Local/NYS_Wetlands_GHG\n",
      "Current working directory is now: /Users/Anthony/Data and Analysis Local/NYS_Wetlands_GHG\n",
      "/Users/Anthony/Data and Analysis Local/NYS_Wetlands_GHG\n",
      "Current working directory is now: /Users/Anthony/Data and Analysis Local/NYS_Wetlands_GHG\n",
      "Class distribution:\n",
      "  Class 0: 19,837,679 pixels (85.99%)\n",
      "  Class 1: 527,896 pixels (2.29%)\n",
      "  Class 2: 1,357,839 pixels (5.89%)\n",
      "  Class 3: 1,157,860 pixels (5.02%)\n",
      "  Class 4: 187,398 pixels (0.81%)\n",
      "\n",
      "Class weights (inverse frequency):\n",
      "  Background: 1.00\n",
      "  EMW: 37.58\n",
      "  FSW: 14.61\n",
      "  SSW: 17.13\n",
      "  OWW: 105.86\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# === SET WORKING DIRECTORY ===\n",
    "workdir = Path(\"/Users/Anthony/Data and Analysis Local/NYS_Wetlands_GHG/\")\n",
    "os.chdir(workdir)\n",
    "\n",
    "# === ADD SCRIPT DIRECTORY TO PYTHON PATH ===\n",
    "script_dir = Path(\"/Users/Anthony/Data and Analysis Local/NYS_Wetlands_GHG/Python_Code_Analysis/DL_Learning\")\n",
    "sys.path.insert(0, str(script_dir))\n",
    "\n",
    "# Now these imports will work\n",
    "from _04_dataset import get_dataloaders\n",
    "from _05_unet_model import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47603f5-d35e-44d1-89fc-07c44c8787df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch and return average loss.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Progress update every 10 batches\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"    Batch {batch_idx + 1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device, num_classes=5):\n",
    "    \"\"\"Validate and return loss plus per-class accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Track correct predictions per class\n",
    "    correct_per_class = torch.zeros(num_classes)\n",
    "    total_per_class = torch.zeros(num_classes)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # Per-class accuracy\n",
    "            for c in range(num_classes):\n",
    "                mask = (y == c)\n",
    "                total_per_class[c] += mask.sum().item()\n",
    "                correct_per_class[c] += ((preds == c) & mask).sum().item()\n",
    "    \n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_acc = {}\n",
    "    class_names = ['Background', 'EMW', 'FSW', 'SSW', 'OWW']\n",
    "    for c in range(num_classes):\n",
    "        if total_per_class[c] > 0:\n",
    "            class_acc[class_names[c]] = correct_per_class[c] / total_per_class[c]\n",
    "        else:\n",
    "            class_acc[class_names[c]] = 0.0\n",
    "    \n",
    "    # Overall accuracy\n",
    "    overall_acc = correct_per_class.sum() / total_per_class.sum()\n",
    "    \n",
    "    return avg_loss, overall_acc.item(), class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8691be53-c8a1-4658-a540-61b84a1765ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "Loading data...\n",
      "Training batches: 29\n",
      "Validation batches: 8\n",
      "\n",
      "Initializing model...\n",
      "\n",
      "Starting training...\n",
      "============================================================\n",
      "\n",
      "Epoch 1/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.6067\n",
      "    Batch 20/29, Loss: 1.5544\n",
      "\n",
      "  Train Loss: 1.5878\n",
      "  Val Loss:   1.4472\n",
      "  Val Acc:    0.4619\n",
      "  Time:       10.3s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.5008\n",
      "    EMW: 0.3267\n",
      "    FSW: 0.3637\n",
      "    SSW: 0.1898\n",
      "    OWW: 0.3200\n",
      "  [Saved new best model]\n",
      "\n",
      "Epoch 2/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.3923\n",
      "    Batch 20/29, Loss: 1.3775\n",
      "\n",
      "  Train Loss: 1.4412\n",
      "  Val Loss:   1.3010\n",
      "  Val Acc:    0.5000\n",
      "  Time:       6.9s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.5145\n",
      "    EMW: 0.0496\n",
      "    FSW: 0.7402\n",
      "    SSW: 0.1109\n",
      "    OWW: 0.7865\n",
      "  [Saved new best model]\n",
      "\n",
      "Epoch 3/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.3928\n",
      "    Batch 20/29, Loss: 1.3258\n",
      "\n",
      "  Train Loss: 1.3424\n",
      "  Val Loss:   1.4098\n",
      "  Val Acc:    0.3014\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.2629\n",
      "    EMW: 0.1217\n",
      "    FSW: 0.7421\n",
      "    SSW: 0.0516\n",
      "    OWW: 0.9537\n",
      "\n",
      "Epoch 4/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.4473\n",
      "    Batch 20/29, Loss: 1.0948\n",
      "\n",
      "  Train Loss: 1.3073\n",
      "  Val Loss:   1.3701\n",
      "  Val Acc:    0.4114\n",
      "  Time:       6.9s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.3857\n",
      "    EMW: 0.0349\n",
      "    FSW: 0.8897\n",
      "    SSW: 0.0921\n",
      "    OWW: 0.9055\n",
      "\n",
      "Epoch 5/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.4386\n",
      "    Batch 20/29, Loss: 1.2702\n",
      "\n",
      "  Train Loss: 1.2946\n",
      "  Val Loss:   1.4099\n",
      "  Val Acc:    0.3650\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.3212\n",
      "    EMW: 0.0411\n",
      "    FSW: 0.9661\n",
      "    SSW: 0.1241\n",
      "    OWW: 0.6229\n",
      "\n",
      "Epoch 6/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.1977\n",
      "    Batch 20/29, Loss: 1.2662\n",
      "\n",
      "  Train Loss: 1.2823\n",
      "  Val Loss:   1.2146\n",
      "  Val Acc:    0.4092\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.3774\n",
      "    EMW: 0.1674\n",
      "    FSW: 0.9228\n",
      "    SSW: 0.0420\n",
      "    OWW: 0.8065\n",
      "  [Saved new best model]\n",
      "\n",
      "Epoch 7/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.2521\n",
      "    Batch 20/29, Loss: 1.2752\n",
      "\n",
      "  Train Loss: 1.2410\n",
      "  Val Loss:   1.3165\n",
      "  Val Acc:    0.5702\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.5731\n",
      "    EMW: 0.1417\n",
      "    FSW: 0.9635\n",
      "    SSW: 0.1760\n",
      "    OWW: 0.4447\n",
      "\n",
      "Epoch 8/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.3608\n",
      "    Batch 20/29, Loss: 1.4525\n",
      "\n",
      "  Train Loss: 1.2288\n",
      "  Val Loss:   1.7984\n",
      "  Val Acc:    0.6113\n",
      "  Time:       6.9s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.7047\n",
      "    EMW: 0.0433\n",
      "    FSW: 0.3171\n",
      "    SSW: 0.0633\n",
      "    OWW: 0.9401\n",
      "\n",
      "Epoch 9/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.1693\n",
      "    Batch 20/29, Loss: 1.0868\n",
      "\n",
      "  Train Loss: 1.2415\n",
      "  Val Loss:   3.7407\n",
      "  Val Acc:    0.2361\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.2425\n",
      "    EMW: 0.0237\n",
      "    FSW: 0.2766\n",
      "    SSW: 0.0252\n",
      "    OWW: 0.9797\n",
      "\n",
      "Epoch 10/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.2846\n",
      "    Batch 20/29, Loss: 1.2249\n",
      "\n",
      "  Train Loss: 1.2016\n",
      "  Val Loss:   1.8118\n",
      "  Val Acc:    0.3991\n",
      "  Time:       7.1s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.3570\n",
      "    EMW: 0.0127\n",
      "    FSW: 0.8805\n",
      "    SSW: 0.5448\n",
      "    OWW: 0.1013\n",
      "\n",
      "Epoch 11/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.2927\n",
      "    Batch 20/29, Loss: 1.3153\n",
      "\n",
      "  Train Loss: 1.2184\n",
      "  Val Loss:   1.0807\n",
      "  Val Acc:    0.5978\n",
      "  Time:       7.1s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.5962\n",
      "    EMW: 0.0841\n",
      "    FSW: 0.9203\n",
      "    SSW: 0.4193\n",
      "    OWW: 0.6355\n",
      "  [Saved new best model]\n",
      "\n",
      "Epoch 12/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.3609\n",
      "    Batch 20/29, Loss: 1.2223\n",
      "\n",
      "  Train Loss: 1.1982\n",
      "  Val Loss:   1.3301\n",
      "  Val Acc:    0.3989\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.3734\n",
      "    EMW: 0.2778\n",
      "    FSW: 0.7419\n",
      "    SSW: 0.1237\n",
      "    OWW: 0.9050\n",
      "\n",
      "Epoch 13/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.3058\n",
      "    Batch 20/29, Loss: 1.3870\n",
      "\n",
      "  Train Loss: 1.1715\n",
      "  Val Loss:   1.1846\n",
      "  Val Acc:    0.4446\n",
      "  Time:       7.1s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.4133\n",
      "    EMW: 0.1241\n",
      "    FSW: 0.8509\n",
      "    SSW: 0.4009\n",
      "    OWW: 0.5551\n",
      "\n",
      "Epoch 14/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.3576\n",
      "    Batch 20/29, Loss: 1.1431\n",
      "\n",
      "  Train Loss: 1.1753\n",
      "  Val Loss:   1.3291\n",
      "  Val Acc:    0.6262\n",
      "  Time:       7.1s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.7096\n",
      "    EMW: 0.1863\n",
      "    FSW: 0.3467\n",
      "    SSW: 0.1220\n",
      "    OWW: 0.9035\n",
      "\n",
      "Epoch 15/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.1774\n",
      "    Batch 20/29, Loss: 1.5831\n",
      "\n",
      "  Train Loss: 1.1852\n",
      "  Val Loss:   1.1352\n",
      "  Val Acc:    0.6831\n",
      "  Time:       7.1s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.7625\n",
      "    EMW: 0.4920\n",
      "    FSW: 0.3660\n",
      "    SSW: 0.1592\n",
      "    OWW: 0.8133\n",
      "\n",
      "Epoch 16/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.0419\n",
      "    Batch 20/29, Loss: 1.0511\n",
      "\n",
      "  Train Loss: 1.1690\n",
      "  Val Loss:   1.0775\n",
      "  Val Acc:    0.6305\n",
      "  Time:       7.1s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.6831\n",
      "    EMW: 0.3477\n",
      "    FSW: 0.5600\n",
      "    SSW: 0.1070\n",
      "    OWW: 0.8806\n",
      "  [Saved new best model]\n",
      "\n",
      "Epoch 17/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 0.9989\n",
      "    Batch 20/29, Loss: 1.0428\n",
      "\n",
      "  Train Loss: 1.1323\n",
      "  Val Loss:   0.9539\n",
      "  Val Acc:    0.6126\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.6301\n",
      "    EMW: 0.5208\n",
      "    FSW: 0.7062\n",
      "    SSW: 0.1876\n",
      "    OWW: 0.8420\n",
      "  [Saved new best model]\n",
      "\n",
      "Epoch 18/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 0.8933\n",
      "    Batch 20/29, Loss: 1.1485\n",
      "\n",
      "  Train Loss: 1.1353\n",
      "  Val Loss:   0.9900\n",
      "  Val Acc:    0.7276\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.7927\n",
      "    EMW: 0.4153\n",
      "    FSW: 0.5461\n",
      "    SSW: 0.3001\n",
      "    OWW: 0.7430\n",
      "\n",
      "Epoch 19/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.3853\n",
      "    Batch 20/29, Loss: 1.2890\n",
      "\n",
      "  Train Loss: 1.1451\n",
      "  Val Loss:   1.2527\n",
      "  Val Acc:    0.7621\n",
      "  Time:       7.2s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.8908\n",
      "    EMW: 0.2386\n",
      "    FSW: 0.2286\n",
      "    SSW: 0.1541\n",
      "    OWW: 0.8061\n",
      "\n",
      "Epoch 20/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.1554\n",
      "    Batch 20/29, Loss: 1.1565\n",
      "\n",
      "  Train Loss: 1.1885\n",
      "  Val Loss:   2.0417\n",
      "  Val Acc:    0.3594\n",
      "  Time:       7.1s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.3503\n",
      "    EMW: 0.0788\n",
      "    FSW: 0.6141\n",
      "    SSW: 0.0906\n",
      "    OWW: 0.9474\n",
      "\n",
      "Epoch 21/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.5139\n",
      "    Batch 20/29, Loss: 1.0845\n",
      "\n",
      "  Train Loss: 1.1610\n",
      "  Val Loss:   1.0625\n",
      "  Val Acc:    0.7396\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.8309\n",
      "    EMW: 0.3910\n",
      "    FSW: 0.4423\n",
      "    SSW: 0.1332\n",
      "    OWW: 0.8170\n",
      "\n",
      "Epoch 22/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.1770\n",
      "    Batch 20/29, Loss: 1.2936\n",
      "\n",
      "  Train Loss: 1.1223\n",
      "  Val Loss:   1.0886\n",
      "  Val Acc:    0.7056\n",
      "  Time:       7.1s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.7875\n",
      "    EMW: 0.3392\n",
      "    FSW: 0.4494\n",
      "    SSW: 0.1578\n",
      "    OWW: 0.8670\n",
      "\n",
      "Epoch 23/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 0.9425\n",
      "    Batch 20/29, Loss: 1.0331\n",
      "\n",
      "  Train Loss: 1.0914\n",
      "  Val Loss:   1.0300\n",
      "  Val Acc:    0.5172\n",
      "  Time:       7.1s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.4990\n",
      "    EMW: 0.3213\n",
      "    FSW: 0.8309\n",
      "    SSW: 0.2807\n",
      "    OWW: 0.8724\n",
      "\n",
      "Epoch 24/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 0.8795\n",
      "    Batch 20/29, Loss: 0.9669\n",
      "\n",
      "  Train Loss: 1.0885\n",
      "  Val Loss:   1.1610\n",
      "  Val Acc:    0.6163\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.6624\n",
      "    EMW: 0.2053\n",
      "    FSW: 0.6062\n",
      "    SSW: 0.1700\n",
      "    OWW: 0.8971\n",
      "\n",
      "Epoch 25/25\n",
      "----------------------------------------\n",
      "    Batch 10/29, Loss: 1.2166\n",
      "    Batch 20/29, Loss: 1.1363\n",
      "\n",
      "  Train Loss: 1.1035\n",
      "  Val Loss:   0.9797\n",
      "  Val Acc:    0.6076\n",
      "  Time:       7.0s\n",
      "  Per-class accuracy:\n",
      "    Background: 0.6096\n",
      "    EMW: 0.2718\n",
      "    FSW: 0.8467\n",
      "    SSW: 0.3467\n",
      "    OWW: 0.8121\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "Best validation loss: 0.9539\n",
      "Models saved to: Models\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # === CONFIGURATION ===\n",
    "    data_dir = Path(\"Data/Patches_v2\")\n",
    "    output_dir = Path(\"Models\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    num_epochs = 25\n",
    "    batch_size = 10\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Class weights from our analysis\n",
    "    class_weights = torch.tensor([1.0, 22.6, 12.88, 13.04, 55.52], dtype=torch.float32)\n",
    "    \n",
    "    # Device (CPU in your case)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if \n",
    "                          torch.backends.mps.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # === LOAD DATA ===\n",
    "    print(\"\\nLoading data...\")\n",
    "    train_loader, val_loader = get_dataloaders(\n",
    "        data_dir / \"X_train.npy\",\n",
    "        data_dir / \"y_train.npy\",\n",
    "        data_dir / \"X_val.npy\",\n",
    "        data_dir / \"y_val.npy\",\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    print(f\"Training batches: {len(train_loader)}\")\n",
    "    print(f\"Validation batches: {len(val_loader)}\")\n",
    "    \n",
    "    # === CREATE MODEL ===\n",
    "    print(\"\\nInitializing model...\")\n",
    "    model = UNet(in_channels=12, num_classes=5, base_filters=32)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # === LOSS AND OPTIMIZER ===\n",
    "    class_weights = class_weights.to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # === TRAINING LOOP ===\n",
    "    print(\"\\nStarting training...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, class_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        # Log results\n",
    "        print(f\"\\n  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "        print(f\"  Val Acc:    {val_acc:.4f}\")\n",
    "        print(f\"  Time:       {epoch_time:.1f}s\")\n",
    "        print(\"  Per-class accuracy:\")\n",
    "        for name, acc in class_acc.items():\n",
    "            print(f\"    {name}: {acc:.4f}\")\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc\n",
    "            }, output_dir / \"best_model.pth\")\n",
    "            print(\"  [Saved new best model]\")\n",
    "    \n",
    "    # === SAVE FINAL MODEL AND HISTORY ===\n",
    "    torch.save({\n",
    "        'epoch': num_epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc\n",
    "    }, output_dir / \"final_model.pth\")\n",
    "    \n",
    "    np.save(output_dir / \"training_history.npy\", history)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Training complete!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"Models saved to: {output_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddb62c-fe9c-47ad-b686-6958e348857e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wetland-cnn",
   "language": "python",
   "name": "wetland-cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
