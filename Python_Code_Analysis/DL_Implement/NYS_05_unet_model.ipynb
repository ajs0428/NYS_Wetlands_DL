{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af908d99-ee5e-49da-89d4-ea4d983539d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/Anthony/Data and Analysis Local/NYS_Wetlands_DL\n",
      "\n",
      "Configuration:\n",
      "  data_dir: Data/Patches_v2\n",
      "  cluster_id: 208\n",
      "  huc_id: All HUCs in cluster\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === CONFIGURATION (only when running notebook directly) ===\n",
    "if __name__ == \"__main__\" or 'get_ipython' in dir():\n",
    "    workdir = Path(\"/Users/Anthony/Data and Analysis Local/NYS_Wetlands_DL/\")\n",
    "    os.chdir(workdir)\n",
    "    print(f\"Current working directory: {Path.cwd()}\")\n",
    "\n",
    "    # Must match the output from NYS_03_create_patches_v2.ipynb\n",
    "    data_dir = Path(\"Data/Patches_v2\")\n",
    "    cluster_id = 208  # Cluster to load, or None for legacy files\n",
    "    huc_id = None     # Specific HUC to load, or None to combine all HUCs in cluster\n",
    "\n",
    "    print(f\"\\nConfiguration:\")\n",
    "    print(f\"  data_dir: {data_dir}\")\n",
    "    print(f\"  cluster_id: {cluster_id}\")\n",
    "    print(f\"  huc_id: {huc_id or 'All HUCs in cluster'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rovtempmitq",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata loaded:\n",
      "  in_channels: 11\n",
      "  num_classes: 2\n",
      "  patch_size: 128\n",
      "  band_names: ['r', 'g', 'b', 'nir', 'ndvi', 'ndwi', 'dem', 'chm', 'slope_5m', 'TPI_5m', 'Geomorph_5m']\n",
      "  n_train: 2638\n",
      "  n_val: 662\n",
      "  HUCs included: ['041402011002', '041402011004', '041402011005', '041402011008', '041402011009', '041402011010', '041402011102', '041402011103', '041402011301']\n"
     ]
    }
   ],
   "source": [
    "# === FILE LOADING UTILITIES ===\n",
    "\n",
    "def find_patch_files(data_dir, cluster_id=None, huc_id=None):\n",
    "    \"\"\"\n",
    "    Find patch files based on cluster/HUC configuration.\n",
    "    \n",
    "    Returns:\n",
    "        dict with keys: X_train, y_train, X_val, y_val, metadata\n",
    "        Each value is a list of file paths (or single path for metadata)\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    if cluster_id is None:\n",
    "        # Legacy mode: look for simple filenames\n",
    "        return {\n",
    "            \"X_train\": [data_dir / \"X_train.npy\"],\n",
    "            \"y_train\": [data_dir / \"y_train.npy\"],\n",
    "            \"X_val\": [data_dir / \"X_val.npy\"],\n",
    "            \"y_val\": [data_dir / \"y_val.npy\"],\n",
    "            \"metadata\": data_dir / \"metadata.json\",\n",
    "        }\n",
    "    \n",
    "    if huc_id is not None:\n",
    "        # Specific HUC\n",
    "        return {\n",
    "            \"X_train\": list(data_dir.glob(f\"cluster_{cluster_id}_X_train_{huc_id}_.npy\")),\n",
    "            \"y_train\": list(data_dir.glob(f\"cluster_{cluster_id}_y_train_{huc_id}_.npy\")),\n",
    "            \"X_val\": list(data_dir.glob(f\"cluster_{cluster_id}_X_val_{huc_id}_.npy\")),\n",
    "            \"y_val\": list(data_dir.glob(f\"cluster_{cluster_id}_y_val_{huc_id}_.npy\")),\n",
    "            \"metadata\": list(data_dir.glob(f\"cluster_{cluster_id}_metadata_{huc_id}.json\"))[0],\n",
    "        }\n",
    "    \n",
    "    # All HUCs in cluster\n",
    "    X_train_files = sorted(data_dir.glob(f\"cluster_{cluster_id}_X_train_*.npy\"))\n",
    "    y_train_files = sorted(data_dir.glob(f\"cluster_{cluster_id}_y_train_*.npy\"))\n",
    "    X_val_files = sorted(data_dir.glob(f\"cluster_{cluster_id}_X_val_*.npy\"))\n",
    "    y_val_files = sorted(data_dir.glob(f\"cluster_{cluster_id}_y_val_*.npy\"))\n",
    "    metadata_files = sorted(data_dir.glob(f\"cluster_{cluster_id}_metadata_*.json\"))\n",
    "    \n",
    "    if not X_train_files:\n",
    "        raise FileNotFoundError(f\"No training files found for cluster {cluster_id} in {data_dir}\")\n",
    "    \n",
    "    return {\n",
    "        \"X_train\": X_train_files,\n",
    "        \"y_train\": y_train_files,\n",
    "        \"X_val\": X_val_files,\n",
    "        \"y_val\": y_val_files,\n",
    "        \"metadata_files\": metadata_files,\n",
    "    }\n",
    "\n",
    "\n",
    "def load_and_merge_metadata(metadata_files):\n",
    "    \"\"\"\n",
    "    Load and merge metadata from multiple HUC files.\n",
    "    \n",
    "    For band_stats, computes global min/max across all files.\n",
    "    For normalization with minmax, updates to use global stats.\n",
    "    \"\"\"\n",
    "    if isinstance(metadata_files, (str, Path)):\n",
    "        # Single file\n",
    "        with open(metadata_files) as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    # Multiple files - merge them\n",
    "    all_metadata = []\n",
    "    for mf in metadata_files:\n",
    "        with open(mf) as f:\n",
    "            all_metadata.append(json.load(f))\n",
    "    \n",
    "    # Start with first file as base\n",
    "    merged = all_metadata[0].copy()\n",
    "    \n",
    "    # Merge band_stats: compute global min/max\n",
    "    band_names = merged[\"band_names\"]\n",
    "    merged_stats = {}\n",
    "    \n",
    "    for band in band_names:\n",
    "        mins = [m[\"band_stats\"][band][\"min\"] for m in all_metadata]\n",
    "        maxs = [m[\"band_stats\"][band][\"max\"] for m in all_metadata]\n",
    "        means = [m[\"band_stats\"][band][\"mean\"] for m in all_metadata]\n",
    "        stds = [m[\"band_stats\"][band][\"std\"] for m in all_metadata]\n",
    "        \n",
    "        merged_stats[band] = {\n",
    "            \"min\": min(mins),\n",
    "            \"max\": max(maxs),\n",
    "            \"mean\": sum(means) / len(means),\n",
    "            \"std\": sum(stds) / len(stds),\n",
    "        }\n",
    "    \n",
    "    merged[\"band_stats\"] = merged_stats\n",
    "    \n",
    "    # Update minmax normalization to use global stats\n",
    "    for band, norm in merged[\"normalization\"].items():\n",
    "        if norm[\"type\"] == \"minmax\":\n",
    "            norm[\"min\"] = merged_stats[band][\"min\"]\n",
    "            norm[\"max\"] = merged_stats[band][\"max\"]\n",
    "    \n",
    "    # Sum up counts\n",
    "    merged[\"n_train\"] = sum(m[\"n_train\"] for m in all_metadata)\n",
    "    merged[\"n_val\"] = sum(m[\"n_val\"] for m in all_metadata)\n",
    "    merged[\"hucs_included\"] = [mf.stem.split(\"_\")[-1] for mf in metadata_files]\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n",
    "# === LOAD METADATA (only when running notebook directly) ===\n",
    "if __name__ == \"__main__\" or 'get_ipython' in dir():\n",
    "    # This block runs in notebook or as main script, but NOT when imported\n",
    "    files = find_patch_files(data_dir, cluster_id, huc_id)\n",
    "\n",
    "    if \"metadata\" in files:\n",
    "        metadata = load_and_merge_metadata(files[\"metadata\"])\n",
    "    else:\n",
    "        metadata = load_and_merge_metadata(files[\"metadata_files\"])\n",
    "\n",
    "    print(f\"\\nMetadata loaded:\")\n",
    "    print(f\"  in_channels: {metadata['in_channels']}\")\n",
    "    print(f\"  num_classes: {metadata['num_classes']}\")\n",
    "    print(f\"  patch_size: {metadata['patch_size']}\")\n",
    "    print(f\"  band_names: {metadata['band_names']}\")\n",
    "    print(f\"  n_train: {metadata.get('n_train', 'N/A')}\")\n",
    "    print(f\"  n_val: {metadata.get('n_val', 'N/A')}\")\n",
    "    if \"hucs_included\" in metadata:\n",
    "        print(f\"  HUCs included: {metadata['hucs_included']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f41d3f3-6971-4503-b222-b9d0a963b674",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e02b45f-7d99-4e31-8ab4-b50782275046",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Two consecutive conv layers with BatchNorm and ReLU.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"ConvBlock followed by MaxPool for downsampling.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = ConvBlock(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x)\n",
    "        pooled = self.pool(conv_out)\n",
    "        return conv_out, pooled  # Return both for skip connection\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"Upsample, concatenate skip connection, then ConvBlock.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(\n",
    "            in_channels, out_channels, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.conv = ConvBlock(out_channels * 2, out_channels)  # *2 for concatenation\n",
    "    \n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, skip], dim=1)  # Concatenate along channel dimension\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"Lightweight U-Net for semantic segmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, num_classes, base_filters=32):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: Number of input bands (from metadata)\n",
    "            num_classes: Number of output classes (from metadata)\n",
    "            base_filters: Number of filters in first layer (doubles each level)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        f = base_filters  # 32\n",
    "        \n",
    "        # Encoder path\n",
    "        self.enc1 = EncoderBlock(in_channels, f)\n",
    "        self.enc2 = EncoderBlock(f, f * 2)\n",
    "        self.enc3 = EncoderBlock(f * 2, f * 4)\n",
    "        self.enc4 = EncoderBlock(f * 4, f * 8)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ConvBlock(f * 8, f * 16)\n",
    "        \n",
    "        # Decoder path\n",
    "        self.dec4 = DecoderBlock(f * 16, f * 8)\n",
    "        self.dec3 = DecoderBlock(f * 8, f * 4)\n",
    "        self.dec2 = DecoderBlock(f * 4, f * 2)\n",
    "        self.dec1 = DecoderBlock(f * 2, f)\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.final = nn.Conv2d(f, num_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        skip1, x = self.enc1(x)\n",
    "        skip2, x = self.enc2(x)\n",
    "        skip3, x = self.enc3(x)\n",
    "        skip4, x = self.enc4(x)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        x = self.dec4(x, skip4)\n",
    "        x = self.dec3(x, skip3)\n",
    "        x = self.dec2(x, skip2)\n",
    "        x = self.dec1(x, skip1)\n",
    "        \n",
    "        # Output\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf05a0e2-f875-4280-a437-094906090d13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 7,768,322\n",
      "Trainable parameters: 7,768,322\n",
      "\n",
      "Input shape: torch.Size([4, 11, 128, 128])\n",
      "Output shape: torch.Size([4, 2, 128, 128])\n",
      "\n",
      "Model architecture verified successfully!\n"
     ]
    }
   ],
   "source": [
    "# === TEST THE MODEL ===\n",
    "if __name__ == \"__main__\" or 'get_ipython' in dir():\n",
    "    in_channels = metadata[\"in_channels\"]\n",
    "    num_classes = metadata[\"num_classes\"]\n",
    "    patch_size = metadata[\"patch_size\"]\n",
    "\n",
    "    # Create model using metadata\n",
    "    model = UNet(in_channels=in_channels, num_classes=num_classes, base_filters=32)\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "    # Test forward pass\n",
    "    dummy_input = torch.randn(4, in_channels, patch_size, patch_size)\n",
    "    print(f\"\\nInput shape: {dummy_input.shape}\")\n",
    "\n",
    "    output = model(dummy_input)\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "    # Verify output is correct shape\n",
    "    expected_shape = (4, num_classes, patch_size, patch_size)\n",
    "    assert output.shape == expected_shape, f\"Output shape mismatch! Expected {expected_shape}, got {output.shape}\"\n",
    "    print(\"\\nModel architecture verified successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ccfbbba-395e-4f6e-abe7-7701a2a2ee50",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 9 y_train file(s)...\n",
      "Combined y_train shape: (2638, 128, 128)\n",
      "\n",
      "Class distribution:\n",
      "  Background (class 0): 33,693,033 pixels (77.96%)\n",
      "  WET (class 1): 9,527,959 pixels (22.04%)\n",
      "\n",
      "Class weights (inverse frequency, normalized):\n",
      "  Background: 1.00\n",
      "  WET: 3.54\n",
      "\n",
      "class_weights tensor: tensor([1.0000, 3.5362])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# === COMPUTE CLASS WEIGHTS FROM TRAINING DATA ===\n",
    "if __name__ == \"__main__\" or 'get_ipython' in dir():\n",
    "    # Load all y_train files and concatenate\n",
    "    print(f\"Loading {len(files['y_train'])} y_train file(s)...\")\n",
    "    y_train_list = [np.load(f) for f in files['y_train']]\n",
    "    y_train = np.concatenate(y_train_list, axis=0)\n",
    "    print(f\"Combined y_train shape: {y_train.shape}\")\n",
    "\n",
    "    # Count pixels per class\n",
    "    classes, counts = np.unique(y_train, return_counts=True)\n",
    "    total = counts.sum()\n",
    "\n",
    "    print(\"\\nClass distribution:\")\n",
    "    class_names = metadata[\"class_names\"]\n",
    "    for c, count in zip(classes, counts):\n",
    "        print(f\"  {class_names[c]} (class {c}): {count:,} pixels ({count/total*100:.2f}%)\")\n",
    "\n",
    "    # Compute inverse frequency weights\n",
    "    frequencies = counts / total\n",
    "    weights = 1.0 / frequencies\n",
    "    weights = weights / weights.min()  # Normalize so smallest weight is 1.0\n",
    "\n",
    "    print(\"\\nClass weights (inverse frequency, normalized):\")\n",
    "    for c, w in zip(classes, weights):\n",
    "        print(f\"  {class_names[c]}: {w:.2f}\")\n",
    "\n",
    "    # Store as tensor for use in loss function\n",
    "    class_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "    print(f\"\\nclass_weights tensor: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "743a907a-d006-42a8-8e73-d68ef089d515",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Python_Code_Analysis/DL_Implement/NYS_05_unet_model.ipynb to script\n",
      "[NbConvertApp] Writing 10127 bytes to Python_Code_Analysis/DL_Implement/NYS_05_unet_model.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script Python_Code_Analysis/DL_Implement/NYS_05_unet_model.ipynb --TagRemovePreprocessor.remove_cell_tags='{\"remove\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe5b7b-8f2a-4a7f-8927-66582b6871a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wetland-cnn",
   "language": "python",
   "name": "wetland-cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
